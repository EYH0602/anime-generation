@book{Daliot2017Anime,
	note = {[Online; accessed 2022-12-04]},
	author = {Daliot-Bul, Michal and Otmazgin, Nissim},
	year = {2017},
	publisher = {Harvard East Asian Monographs},
	title = {The {Anime} {Boom} in the {United} {States}: Lessons for {Global} {Creative} {Industries}},
}
@inproceedings{Ruan2022Anime,
	note = {[Online; accessed 2022-12-04]},
	author = {Ruan, Shengrui},
	booktitle = {2022 {IEEE} {International} {Conference} on {Advances} in {Electrical} {Engineering} and {Computer} {Applications} ({AEECA})},
	year = {2022},
	month = {aug 20},
	organization = {IEEE},
	title = {Anime {Characters} {Generation} with {Generative} {Adversarial} {Networks}},
}
@misc{Jin2017Towards,
	author = {Jin, Yanghua and Zhang, Jiakai and Li, Minjun and Tian, Yingtao and Zhu, Huachun and Fang, Zhihao},
	year = {2017},
	month = {aug 18},
	title = {Towards the {Automatic} {Anime} {Characters} {Creation} with {Generative} {Adversarial} {Networks}},
	howpublished = {https://arxiv.org/abs/1708.05509},
}
@book{Lamarre2018Anime,
	note = {[Online; accessed 2022-12-04]},
	author = {Lamarre, Thomas},
	year = {2018},
	publisher = {University of Minnesota Press},
	title = {The {Anime} {Ecology}: A {Genealogy} of {Television}, {Animation}, and {Game} {Media}},
}
@misc{Metz2022This,
	note = {[Online; accessed 2022-12-04]},
	author = {Metz, Rachel},
	year = {2022},
	month = {jul 14},
	title = {This {AI} image generator lets you type in words and get weird pictures back},
	howpublished = {https://www.cnn.com/2022/07/14/tech/craiyon-dalle-mini-ai/index.html.},
}
@article{Morisawa2014Managing,
	note = {[Online; accessed 2022-12-04]},
	author = {Morisawa, Tomohiro},
	journal = {Ethnography},
	number = {2},
	year = {2014},
	month = {aug 19},
	pages = {262--284},
	publisher = {SAGE Publications},
	title = {Managing the unmanageable: Emotional labour and creative hierarchy in the {Japanese} animation industry},
	volume = {16},
}
@inproceedings{Rombach2022High,
	note = {[Online; accessed 2022-12-04]},
	author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bjorn},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	year = {2022},
	month = {6},
	organization = {IEEE},
	title = {High-{Resolution} {Image} {Synthesis} with {Latent} {Diffusion} {Models}},
}
@misc{Teoh2022Art,
	note = {[Online; accessed 2022-12-04]},
	author = {Teoh, Belinda},
	year = {2022},
	month = {sep 13},
	title = {Art {Made} by {AI} {Wins} {Fine} {Arts} {Competition} - {Impakter}},
	howpublished = {https://impakter.com/art-made-by-ai-wins-fine-arts-competition/.},
}
@misc{Aoi2022Stable,
	note = {[Online; accessed 2022-12-04]},
	author = {Aoi, Len},
	year = {2022},
	month = {aug 25},
	title = {Stable {Diffusion} and {Midjourney} can even understand ``kawaii.'' {Anime}-style characters created by {AI} image generators},
	howpublished = {https://automaton-media.com/en/news/20220825-15224/.},
}
@inproceedings{Karras2020Analyzing,
    note = {[Online; accessed 2022-12-04]},
    author = {Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
    booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
    year = {2020},
    month = {6},
    organization = {IEEE},
    title = {Analyzing and {Improving} the {Image} {Quality} of {StyleGAN}},
}

@inproceedings{pmlr-v37-gregor15,
  title = 	 {DRAW: A Recurrent Neural Network For Image Generation},
  author = 	 {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo and Wierstra, Daan},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1462--1471},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/gregor15.pdf},
  abstract = 	 {This paper introduces the Deep Recurrent Attentive Writer (DRAW) architecture for image generation with neural networks. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it is able to generate images that are indistinguishable from real data with the naked eye.}
}
@InProceedings{Qiao_2019_CVPR,
author = {Qiao, Tingting and Zhang, Jing and Xu, Duanqing and Tao, Dacheng},
title = {MirrorGAN: Learning Text-To-Image Generation by Redescription},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
},
@inproceedings{NEURIPS2019_1d72310e,
 author = {Li, Bowen and Qi, Xiaojuan and Lukasiewicz, Thomas and Torr, Philip},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Controllable Text-to-Image Generation},
 url = {https://proceedings.neurips.cc/paper/2019/file/1d72310edc006dadf2190caad5802983-Paper.pdf},
 volume = {32},
 year = {2019}
}
@inproceedings{NIPS2016_b1301141,
 author = {van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and kavukcuoglu, koray and Vinyals, Oriol and Graves, Alex},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Conditional Image Generation with PixelCNN Decoders},
 url = {https://proceedings.neurips.cc/paper/2016/file/b1301141feffabac455e1f90a7de2054-Paper.pdf},
 volume = {29},
 year = {2016}
}
@article{Goodfellow2020Generative,
    note = {[Online; accessed 2022-12-05]},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    journal = {Communications of the ACM},
    number = {11},
    year = {2020},
    month = {oct 22},
    pages = {139--144},
    publisher = {Association for Computing Machinery (ACM)},
    title = {Generative adversarial networks},
    volume = {63},
}
@InProceedings{He_2022_CVPR,
    author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll\'ar, Piotr and Girshick, Ross},
    title     = {Masked Autoencoders Are Scalable Vision Learners},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16000-16009}
}
@website{Midjourney,
	year = {2022},
	title = {Midjourney.com},
	url = {https://www.midjourney.com}
}

@book{Yano2013Pink,
    note = {[Online; accessed 2022-12-04]},
    author = {Yano, Christine R.},
    year = {2013},
    month = {apr 29},
    pages = {153--167},
    publisher = {Duke University Press},
    title = {Pink {Globalization}: Hello {Kitty}'s {Trek} {Across} the {Pacific}},
}

@software{WaifuDiffusion,
author = {harubaru},
title = {{Waifu Diffusion}},
url = {https://github.com/harubaru/waifu-diffusion},
year = {2022}
}

@misc{chong2021gans,
      title={GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)}, 
      author={Min Jin Chong and David Forsyth},
      year={2021},
      eprint={2106.06561},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{chong2021jojogan,
  title={JoJoGAN: One Shot Face Stylization},
  author={Chong, Min Jin and Forsyth, David},
  journal={arXiv preprint arXiv:2112.11641},
  year={2021}
}
